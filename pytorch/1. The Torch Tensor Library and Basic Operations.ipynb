{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tutorial\n",
    "\n",
    "IFT6135 â€“ Representation Learning\n",
    "\n",
    "A Deep Learning Course, January 2019\n",
    "\n",
    "By Chin-Wei Huang \n",
    "\n",
    "(Adapted from Sandeep Subramanian's MILA welcome tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to the torch tensor library\n",
    "### Torch's numpy equivalent with GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -1.5846e+29,  1.2648e+30],\n",
       "        [-4.6577e-10,  9.8091e-45,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  2.8167e-36,  1.4013e-45],\n",
       "        [ 1.4013e-45,  1.4013e-45,  0.0000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8009,  0.5040,  0.1534],\n",
      "        [ 0.5600,  0.5908,  0.6128],\n",
      "        [ 0.9355, -0.0888, -0.0967],\n",
      "        [ 0.0137, -0.2659,  0.1849],\n",
      "        [-0.1018,  0.4046,  0.6622]])\n",
      "tensor([[-0.9577,  0.0755, -0.9721],\n",
      "        [-0.2880, -0.8543, -0.9403],\n",
      "        [-0.9231,  0.2749, -0.4742],\n",
      "        [-0.7808,  0.9098, -0.2767],\n",
      "        [ 0.3118, -0.3696,  0.1999]])\n"
     ]
    }
   ],
   "source": [
    "# intialization\n",
    "print(torch.Tensor(5, 3).uniform_(-1, 1))\n",
    "# sampling\n",
    "print(torch.rand(5,3)*2-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get it's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3).uniform_(-1, 1)\n",
    "print(x.size())\n",
    "\n",
    "# or your favorite np_array.shape\n",
    "print(x.shape)\n",
    "\n",
    "# dimensionality of the 0'th axis?\n",
    "# print(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Types\n",
    "source: http://pytorch.org/docs/master/tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Data type |Tensor|\n",
    "|----------|------|\n",
    "|32-bit floating point|\ttorch.FloatTensor|\n",
    "|64-bit floating point|\ttorch.DoubleTensor|\n",
    "|16-bit floating point|\ttorch.HalfTensor|\n",
    "|8-bit integer (unsigned)|torch.ByteTensor|\n",
    "|8-bit integer (signed)|torch.CharTensor|\n",
    "|16-bit integer (signed)|torch.ShortTensor|\n",
    "|32-bit integer (signed)|torch.IntTensor|\n",
    "|64-bit integer (signed)|torch.LongTensor|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation from lists & numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "z = torch.LongTensor([[1, 3], [2, 9]])\n",
    "print(z.type())\n",
    "# Cast to numpy ndarray\n",
    "print(z.numpy().dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.DoubleTensor\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Data type inferred from numpy\n",
    "print(torch.from_numpy(np.random.rand(5, 3)).type())\n",
    "print(torch.from_numpy(np.random.rand(5, 3).astype(np.float32)).type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples of type error\n",
    "a = torch.randn(1) # x ~ N(0,1)\n",
    "b = torch.from_numpy(np.ones(1))\n",
    "\n",
    "# x+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1101, -0.0261,  0.1083],\n",
      "        [-1.0404,  0.6263,  0.0480],\n",
      "        [ 0.6126, -0.0869, -0.9221],\n",
      "        [-1.0400,  0.1578, -0.0808],\n",
      "        [ 0.7122,  0.0020, -0.1533]])\n"
     ]
    }
   ],
   "source": [
    "y = x * torch.randn(5, 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2838,  0.4611, -0.1417],\n",
      "        [-0.2973,  0.7785,  0.5817],\n",
      "        [-0.5421, -0.9583,  0.2067],\n",
      "        [ 1.1128, -1.9531,  3.9510],\n",
      "        [ 0.9134,  0.0061, -3.3608]])\n"
     ]
    }
   ],
   "source": [
    "noise = torch.randn(5, 3)\n",
    "y = x / torch.sqrt(noise ** 2)\n",
    "# equal to torch.abs\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "tensor([[ 0.4557,  0.3413, -0.3695],\n",
      "        [-0.3426,  0.8451,  0.9206],\n",
      "        [-0.6317, -0.4046,  0.3733],\n",
      "        [ 0.7993, -0.2102,  0.3512],\n",
      "        [ 0.6476,  0.0046, -0.4898]])\n",
      "tensor([[ 1.4557,  1.3413,  0.6305],\n",
      "        [ 0.6574,  1.8451,  1.9206],\n",
      "        [ 0.3683,  0.5954,  1.3733],\n",
      "        [ 1.7993,  0.7898,  1.3512],\n",
      "        [ 1.6476,  1.0046,  0.5102]])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x)\n",
    "y = x + torch.ones(5, 1)\n",
    "print(y)\n",
    "# print(x + torch.arange(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 15])\n",
      "torch.Size([50, 15])\n",
      "torch.Size([50, 1, 15])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn(5, 10, 15)\n",
    "print(y.size())\n",
    "print(y.view(-1, 15).size())  # Same as doing y.view(50, 15)\n",
    "print(y.view(-1, 15).unsqueeze(1).size()) # Adds a dimension at index 1.\n",
    "#print(y.view(-1, 15).unsqueeze(1).squeeze().size())\n",
    "# If input is of shape: (Ax1xBxCx1xD)(Ax1xBxCx1xD) then the out Tensor will be of shape: (AxBxCxD)(AxBxCxD)\n",
    "print()\n",
    "#print(y.transpose(0, 1).size())\n",
    "#print(y.transpose(1, 2).size())\n",
    "#print(y.transpose(0, 1).transpose(1, 2).size())\n",
    "#print(y.permute(1, 2, 0).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 100, 15])\n",
      "torch.Size([50, 100, 15])\n"
     ]
    }
   ],
   "source": [
    "print(y.view(-1, 15).unsqueeze(1).expand(50, 100, 15).size())\n",
    "print(y.view(-1, 15).unsqueeze(1).expand_as(torch.randn(50, 100, 15)).size())\n",
    "# don't confuse it with tensor.repeat ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 30])\n",
      "torch.Size([2, 5, 10, 15])\n"
     ]
    }
   ],
   "source": [
    "# 2 is the dimension over which the tensors are concatenated\n",
    "print(torch.cat([y, y], 2).size())\n",
    "# stack concatenates the sequence of tensors along a new dimension.\n",
    "print(torch.stack([y, y], 0).size())\n",
    "\n",
    "# Q: how to do tensor.stack using cat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 4])\n",
      "tensor([ 1,  0])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn(2, 3, 4)\n",
    "print(y[[1, 0, 1, 1]].size())\n",
    "\n",
    "# PyTorch doesn't support negative strides yet so ::-1 does not work.\n",
    "rev_idx = torch.arange(1, -1, -1).long()\n",
    "print(rev_idx)\n",
    "print(y[rev_idx].size())\n",
    "\n",
    "\n",
    "# gather(input, dim, index)\n",
    "# v = torch.arange(12).view(3,4)\n",
    "# [0,1,2,3]\n",
    "# [4,5,6,7]\n",
    "# [8,9,10,11]\n",
    "# want to return [1,6,8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2456  1.1543  0.5376  0.4358 -0.0369\n",
       " 0.8247 -0.4143 -0.7188  0.3953  0.2573\n",
       "-0.1346  0.7329  0.5156  0.0864 -0.1349\n",
       "-0.3555  0.3135  0.3921 -0.1428 -0.1368\n",
       "-0.4385  0.5601  0.6533 -0.2793 -0.5220\n",
       "[torch.cuda.HalfTensor of size 5x5 (GPU 0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cuda.HalfTensor(5, 3).uniform_(-1, 1)\n",
    "y = torch.cuda.HalfTensor(3, 5).uniform_(-1, 1)\n",
    "torch.matmul(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move tensors on the CPU -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.3758 -0.1090  0.7911\n",
      " 0.2839 -0.9136  0.1070\n",
      " 0.9184  0.5113 -0.8040\n",
      "-0.3412 -0.8895 -0.5780\n",
      "-0.0992  0.0983  0.6074\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      "-0.3758 -0.1090  0.7911\n",
      " 0.2839 -0.9136  0.1070\n",
      " 0.9184  0.5113 -0.8040\n",
      "-0.3412 -0.8895 -0.5780\n",
      "-0.0992  0.0983  0.6074\n",
      "[torch.cuda.FloatTensor of size 5x3 (GPU 0)]\n",
      "\n",
      "\n",
      "-0.3758 -0.1090  0.7911\n",
      " 0.2839 -0.9136  0.1070\n",
      " 0.9184  0.5113 -0.8040\n",
      "-0.3412 -0.8895 -0.5780\n",
      "-0.0992  0.0983  0.6074\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(5, 3).uniform_(-1, 1)\n",
    "print(x)\n",
    "x = x.cuda(device=0)\n",
    "print(x)\n",
    "x = x.cpu()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Contiguity in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.4740 -0.9209  0.4143\n",
      "-0.3473  0.4474 -0.8159\n",
      "-0.7654 -0.0956  0.6145\n",
      "-0.0846 -0.6239  0.8609\n",
      "-0.8142  0.9289 -0.7020\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      " 0.4740 -0.9209  0.4143\n",
      "-0.3473  0.4474 -0.8159\n",
      "-0.7654 -0.0956  0.6145\n",
      "-0.0846 -0.6239  0.8609\n",
      "-0.8142  0.9289 -0.7020\n",
      "[torch.cuda.FloatTensor of size 5x3 (GPU 0)]\n",
      "\n",
      "Contiguity : True \n",
      "Contiguity : False \n",
      "Contiguity : True \n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(5, 3).uniform_(-1, 1)\n",
    "print(x)\n",
    "x = x.cuda(device=0)\n",
    "print(x)\n",
    "print('Contiguity : %s ' % (x.is_contiguous()))\n",
    "x = x.unsqueeze(0).expand(30, 5, 3)\n",
    "print('Contiguity : %s ' % (x.is_contiguous()))\n",
    "x = x.contiguous()\n",
    "print('Contiguity : %s ' % (x.is_contiguous()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
